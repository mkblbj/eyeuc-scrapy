# ğŸ¯ ä¸€é”®çˆ¬å–æŒ‡å—

## ğŸš€ è¶…ç®€å•ï¼šsmart_crawl.sh

**ä¸€æ¡å‘½ä»¤æå®šæ‰€æœ‰ï¼è‡ªåŠ¨å¹¶è¡Œã€è‡ªåŠ¨åˆå¹¶ã€è‡ªåŠ¨å¯¼å…¥ã€‚**

### åŸºç¡€ç”¨æ³•

```bash
./smart_crawl.sh <list_id> <total_pages>
```

### ç¤ºä¾‹

```bash
# è‡ªåŠ¨çˆ¬å– list 182 çš„ 100 é¡µ
./smart_crawl.sh 182 100

# è‡ªåŠ¨çˆ¬å– list 193 çš„ 5 é¡µ
./smart_crawl.sh 193 5
```

### ç‰¹æ€§

- âœ… **è‡ªåŠ¨é€‰æ‹©æœ€ä½³å¹¶è¡Œæ•°**
  - â‰¤10 é¡µ â†’ 1 è¿›ç¨‹
  - â‰¤30 é¡µ â†’ 2 è¿›ç¨‹
  - â‰¤50 é¡µ â†’ 3 è¿›ç¨‹
  - â‰¤75 é¡µ â†’ 4 è¿›ç¨‹
  - â‰¤100 é¡µ â†’ 5 è¿›ç¨‹ âš¡
  - â‰¤150 é¡µ â†’ 6 è¿›ç¨‹
  - â‰¤200 é¡µ â†’ 8 è¿›ç¨‹
  - >200 é¡µ â†’ 10 è¿›ç¨‹

- âœ… **å®æ—¶è¿›åº¦æ¡**
  ```
  è¿›åº¦: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60% (3/5)
  ```

- âœ… **è‡ªåŠ¨åˆå¹¶ç»“æœ**
- âœ… **è‡ªåŠ¨ç»Ÿè®¡æ•°æ®**
- âœ… **å¯é€‰è‡ªåŠ¨å¯¼å…¥æ•°æ®åº“**

---

## ğŸ›ï¸ çµæ´»æ§åˆ¶ï¼šparallel_crawl.sh

**éœ€è¦æ›´å¤šæ§åˆ¶æ—¶ä½¿ç”¨ã€‚**

### åŸºç¡€ç”¨æ³•

```bash
./parallel_crawl.sh <list_id> <total_pages> [parallel_jobs] [batch_size] [cookies]
```

### ç¤ºä¾‹

```bash
# é»˜è®¤ 4 è¿›ç¨‹
./parallel_crawl.sh 182 100

# æŒ‡å®š 8 è¿›ç¨‹
./parallel_crawl.sh 182 100 8

# è‡ªå®šä¹‰æ‰¹æ¬¡å¤§å°
./parallel_crawl.sh 182 100 4 10
```

### ç‰¹æ€§

- âœ… **æ‰‹åŠ¨æŒ‡å®šå¹¶è¡Œæ•°**
- âœ… **è‡ªå®šä¹‰æ‰¹æ¬¡å¤§å°**
- âœ… **è¯¦ç»†çš„ä»»åŠ¡åˆ†é…ä¿¡æ¯**
- âœ… **ä¿å­˜ PID æ–¹ä¾¿ç®¡ç†**
- âš ï¸ **éœ€è¦æ‰‹åŠ¨åˆå¹¶ç»“æœ**

---

## ğŸ“Š ä¸‰ç§æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆ 1ï¼šsmart_crawl.shï¼ˆæ¨è ğŸŒŸï¼‰

```bash
./smart_crawl.sh 182 100
```

| ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|
| âœ… ä¸€æ¡å‘½ä»¤å…¨æå®š | âš ï¸ è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜ï¼Œä¸é€‚åˆå¾®è°ƒ |
| âœ… è‡ªåŠ¨å¹¶è¡Œ | |
| âœ… è‡ªåŠ¨åˆå¹¶ | |
| âœ… å®æ—¶è¿›åº¦æ¡ | |
| âœ… å¯é€‰è‡ªåŠ¨å¯¼å…¥ | |

**é€‚åˆï¼š** æ—¥å¸¸ä½¿ç”¨ã€å¿«é€ŸæŠ“å–ã€æ‡’äººå¿…å¤‡

---

### æ–¹æ¡ˆ 2ï¼šparallel_crawl.sh

```bash
./parallel_crawl.sh 182 100 4
# å®Œæˆåæ‰‹åŠ¨åˆå¹¶
python3 merge_batches.py 182
```

| ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|
| âœ… å¯æ§æ€§å¼º | âš ï¸ éœ€è¦æ‰‹åŠ¨åˆå¹¶ |
| âœ… è‡ªå®šä¹‰å‚æ•° | âš ï¸ å¤šä¸€æ­¥æ“ä½œ |
| âœ… é€‚åˆå¤æ‚åœºæ™¯ | |

**é€‚åˆï¼š** éœ€è¦ç²¾ç»†æ§åˆ¶ã€å¤§è§„æ¨¡æŠ“å–ã€é«˜çº§ç”¨æˆ·

---

### æ–¹æ¡ˆ 3ï¼šæ‰‹åŠ¨å¹¶è¡Œï¼ˆåŸå§‹æ–¹æ³•ï¼‰

```bash
# æ‰‹åŠ¨å¼€å¤šä¸ªç»ˆç«¯
./batch_crawl.sh 182 50 5 cookies.json 1 &
./batch_crawl.sh 182 100 5 cookies.json 51 &
wait
python3 merge_batches.py 182
```

| ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|
| âœ… æœ€å¤§çµæ´»æ€§ | âŒ å¤ªéº»çƒ¦ |
| âœ… å®Œå…¨å¯æ§ | âŒ å®¹æ˜“å‡ºé”™ |
| | âŒ éœ€è¦æ‰‹åŠ¨è®¡ç®—èŒƒå›´ |

**é€‚åˆï¼š** ç‰¹æ®Šéœ€æ±‚ã€è°ƒè¯•ã€å­¦ä¹ åŸç†

---

## ğŸ¯ ä½¿ç”¨å»ºè®®

### å¿«é€ŸæŠ“å–ï¼ˆæ¨èï¼‰

```bash
# å°åˆ—è¡¨ï¼ˆ< 10 é¡µï¼‰
./smart_crawl.sh 193 5

# ä¸­ç­‰åˆ—è¡¨ï¼ˆ< 100 é¡µï¼‰
./smart_crawl.sh 182 100

# å¤§åˆ—è¡¨ï¼ˆ> 100 é¡µï¼‰
./smart_crawl.sh 182 200
```

### é«˜çº§æ§åˆ¶

```bash
# éœ€è¦æ›´å¤šå¹¶è¡Œï¼ˆ8 æ ¸ CPUï¼‰
./parallel_crawl.sh 182 200 8

# å‡å°‘æ‰¹æ¬¡å¤§å°ï¼ˆæé«˜ç¨³å®šæ€§ï¼‰
./parallel_crawl.sh 182 100 4 3

# å¤§æ‰¹æ¬¡ï¼ˆæé«˜é€Ÿåº¦ï¼‰
./parallel_crawl.sh 182 100 2 10
```

### åˆ†æ‰¹æŠ“å–ï¼ˆæ–­ç‚¹ç»­æŠ“ï¼‰

```bash
# ç¬¬ä¸€æ¬¡ï¼šæŠ“å‰ 50 é¡µ
./smart_crawl.sh 182 50

# ç¬¬äºŒæ¬¡ï¼šç»§ç»­æŠ“ 51-100 é¡µ
./parallel_crawl.sh 182 100 4 5 cookies.json 51

# åˆå¹¶æ‰€æœ‰
python3 merge_batches.py 182
```

---

## ğŸ” ç›‘æ§ä¸ç®¡ç†

### æŸ¥çœ‹è¿è¡Œä¸­çš„ä»»åŠ¡

```bash
# æŸ¥çœ‹æ‰€æœ‰çˆ¬è™«è¿›ç¨‹
ps aux | grep batch_crawl

# æŸ¥çœ‹æ—¥å¿—
tail -f logs/list182_*/job0*.log

# æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—çš„æœ€æ–°çŠ¶æ€
ls -lh logs/list182_*/
tail logs/list182_*/*.log
```

### åœæ­¢ä»»åŠ¡

```bash
# æ‰¾åˆ° PID æ–‡ä»¶
ls logs/list182_*/pids.txt

# åœæ­¢æ‰€æœ‰ä»»åŠ¡
kill $(cat logs/list182_TIMESTAMP/pids.txt)

# æˆ–è€…ç›´æ¥æ€æ‰æ‰€æœ‰
pkill -f batch_crawl
```

### æŸ¥çœ‹ç»“æœ

```bash
# æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶
ls -lh per_list_output/

# ç»Ÿè®¡ items
wc -l per_list_output/eyeuc_list182_*_merged_*.jsonl

# æ£€æŸ¥æ—¶é—´å­—æ®µè¦†ç›–ç‡
python3 -c "
import json
total = has_created = has_updated = 0
with open('per_list_output/eyeuc_list182_nba2k25_merged_*.jsonl', 'r') as f:
    for line in f:
        data = json.loads(line)
        total += 1
        if data.get('metadata', {}).get('created_at'): has_created += 1
        if data.get('metadata', {}).get('last_updated'): has_updated += 1
print(f'æ€»è®¡: {total}')
print(f'created_at: {has_created}/{total} ({has_created*100//total}%)')
print(f'last_updated: {has_updated}/{total} ({has_updated*100//total}%)')
"
```

---

## âš¡ æ€§èƒ½å¯¹æ¯”

### List 182 (100 é¡µ, ~2400 items)

| æ–¹æ¡ˆ | å‘½ä»¤ | è€—æ—¶ | æ‰‹åŠ¨æ“ä½œ |
|------|------|------|---------|
| é¡ºåºæŠ“å– | `./batch_crawl.sh 182 100 5` | ~80 åˆ†é’Ÿ | å¼€ 1 ä¸ªç»ˆç«¯ |
| æ‰‹åŠ¨å¹¶è¡Œ | å¼€ 4 ä¸ªç»ˆç«¯åˆ†åˆ«è¿è¡Œ | ~20 åˆ†é’Ÿ | å¼€ 4 ä¸ªç»ˆç«¯ ğŸ˜° |
| parallel_crawl.sh | `./parallel_crawl.sh 182 100 4` | ~20 åˆ†é’Ÿ | å¼€ 1 ä¸ªç»ˆç«¯ âœ… |
| smart_crawl.sh | `./smart_crawl.sh 182 100` | ~20 åˆ†é’Ÿ | å¼€ 1 ä¸ªç»ˆç«¯ ğŸŒŸ |

### List 182 (200 é¡µ, ~4800 items)

| æ–¹æ¡ˆ | å‘½ä»¤ | è€—æ—¶ | å¹¶è¡Œæ•° |
|------|------|------|--------|
| smart_crawl.sh | `./smart_crawl.sh 182 200` | ~30 åˆ†é’Ÿ | 8 è¿›ç¨‹ï¼ˆè‡ªåŠ¨ï¼‰ |
| parallel_crawl.sh | `./parallel_crawl.sh 182 200 8` | ~30 åˆ†é’Ÿ | 8 è¿›ç¨‹ï¼ˆæ‰‹åŠ¨ï¼‰ |
| é¡ºåºæŠ“å– | `./batch_crawl.sh 182 200 5` | ~160 åˆ†é’Ÿ | 1 è¿›ç¨‹ |

**èŠ‚çœæ—¶é—´ï¼š** 80% âš¡

---

## ğŸ› ï¸ æ•…éšœæ’é™¤

### é—®é¢˜ 1ï¼šæ‰€æœ‰ä»»åŠ¡ç«‹å³å®Œæˆä½†æ²¡æœ‰è¾“å‡º

**å¯èƒ½åŸå› ï¼š** cookies è¿‡æœŸ

```bash
# æ£€æŸ¥ cookies
cat cookies.json

# é‡æ–°è·å– cookiesï¼ˆæµè§ˆå™¨ DevTools â†’ Application â†’ Cookiesï¼‰
```

### é—®é¢˜ 2ï¼šæŸäº›ä»»åŠ¡å¡ä½ä¸åŠ¨

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# 1. æ‰¾åˆ°å¡ä½çš„ä»»åŠ¡
ps aux | grep batch_crawl

# 2. æ€æ‰è¯¥ä»»åŠ¡
kill <PID>

# 3. é‡æ–°è¿è¡Œé‚£ä¸ªèŒƒå›´
./batch_crawl.sh 182 50 5 cookies.json 26

# 4. é‡æ–°åˆå¹¶
python3 merge_batches.py 182
```

### é—®é¢˜ 3ï¼šåˆå¹¶å items æ•°é‡ä¸å¯¹

**æ£€æŸ¥ï¼š**

```bash
# æŸ¥çœ‹æ‰€æœ‰åˆ†æ‰¹æ–‡ä»¶
ls -lh per_list_output/eyeuc_list182_*_p*.jsonl

# æ¯ä¸ªæ–‡ä»¶çš„ items æ•°
wc -l per_list_output/eyeuc_list182_*_p*.jsonl

# åˆå¹¶åçš„æ€»æ•°
wc -l per_list_output/eyeuc_list182_*_merged_*.jsonl
```

**ä¿®å¤ï¼š** å¦‚æœæŸä¸ªæ‰¹æ¬¡æ–‡ä»¶ä¸ºç©ºæˆ–å¾ˆå°ï¼Œé‡æ–°æŠ“å–é‚£ä¸ªèŒƒå›´ã€‚

### é—®é¢˜ 4ï¼šå†…å­˜/CPU å ç”¨è¿‡é«˜

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# å‡å°‘å¹¶è¡Œæ•°
./parallel_crawl.sh 182 100 2  # ä» 4 é™åˆ° 2

# æˆ–å¢åŠ æ‰¹æ¬¡é—´éš”
# ä¿®æ”¹ parallel_crawl.sh ä¸­çš„ sleep 2 æ”¹ä¸º sleep 5
```

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. é¦–æ¬¡æŠ“å–

```bash
# å…ˆæŠ“ 5 é¡µæµ‹è¯•
./smart_crawl.sh 182 5

# æ£€æŸ¥ç»“æœ
tail per_list_output/eyeuc_list182_*.jsonl

# å¦‚æœ OKï¼Œå…¨é‡æŠ“å–
./smart_crawl.sh 182 100
```

### 2. å®šæ—¶æŠ“å–ï¼ˆæ›´æ–°æ•°æ®ï¼‰

```bash
# åˆ›å»º cron ä»»åŠ¡
crontab -e

# æ¯å¤©å‡Œæ™¨ 2 ç‚¹æŠ“å–
0 2 * * * cd /root/dev/eyeuc-scrapy && ./smart_crawl.sh 182 100 >> logs/cron.log 2>&1
```

### 3. æ‰¹é‡æŠ“å–å¤šä¸ªåˆ—è¡¨

```bash
#!/bin/bash
# batch_all.sh
for list_id in 182 193 172; do
    echo "æŠ“å– list $list_id..."
    ./smart_crawl.sh $list_id 100
    sleep 60  # åˆ—è¡¨ä¹‹é—´é—´éš” 1 åˆ†é’Ÿ
done
```

### 4. ç½‘ç»œä¸ç¨³å®šæ—¶

```bash
# å‡å°æ‰¹æ¬¡ï¼Œå¢åŠ å¹¶è¡Œ
./parallel_crawl.sh 182 100 8 3

# 3 é¡µä¸€æ‰¹ï¼Œ8 ä¸ªå¹¶è¡Œ â†’ æ›´å¿«å¤±è´¥é‡è¯•
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- ğŸ“„ `PARALLEL_CRAWL_GUIDE.md` - å¹¶è¡Œçˆ¬å–åŸç†è¯¦è§£
- ğŸ“„ `BATCH_CRAWL_GUIDE.md` - æ‰¹æ¬¡çˆ¬å–å®Œæ•´æŒ‡å—
- ğŸ“„ `DATABASE_IMPORT_README.md` - æ•°æ®åº“å¯¼å…¥è¯´æ˜
- ğŸ“„ `TIME_FIX_SUMMARY.md` - æ—¶é—´å­—æ®µä¿®å¤è¯´æ˜

---

## ğŸ‰ æ€»ç»“

### æ—¥å¸¸ä½¿ç”¨ï¼ˆæ¨èï¼‰

```bash
./smart_crawl.sh <list_id> <pages>
```

### éœ€è¦æ§åˆ¶

```bash
./parallel_crawl.sh <list_id> <pages> <jobs>
```

### ç‰¹æ®Šåœºæ™¯

```bash
# æ‰‹åŠ¨å¹¶è¡Œ + åˆå¹¶
./batch_crawl.sh ... &
./batch_crawl.sh ... &
wait
python3 merge_batches.py <list_id>
```

**ä»æ­¤å‘Šåˆ«æ‰‹åŠ¨å¼€ 5 ä¸ªç»ˆç«¯ï¼** ğŸŠ

