#!/usr/bin/env python3
"""
EyeUC JSONL â†’ MySQL å¯¼å…¥è„šæœ¬

åŠŸèƒ½ï¼š
- æ”¯æŒ JSONL å’Œ JSON æ•°ç»„æ ¼å¼
- æ”¯æŒç›®å½• glob æ‰¹é‡å¯¼å…¥
- å¹‚ç­‰å¯¼å…¥ï¼ˆON DUPLICATE KEY UPDATEï¼‰
- æ‰¹é‡æäº¤ï¼ˆæ¯ 200 æ¡ï¼‰
- å¯¼å…¥æˆåŠŸåè‡ªåŠ¨æ¸…ç†æºæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
- å…¨é‡æ›¿æ¢æ¨¡å¼ï¼šåˆ é™¤æ‰€æœ‰æ—§æ•°æ®åå¯¼å…¥ï¼ˆå¯é€‰ï¼‰

ç”¨æ³•ï¼š
  # å¢é‡å¯¼å…¥ï¼ˆé»˜è®¤ï¼‰- æ›´æ–°å·²æœ‰æ•°æ®ï¼Œæ·»åŠ æ–°æ•°æ®
  python scripts/import_eyeuc_jsonl_to_mysql.py per_list_output/eyeuc_list193_merged_*.jsonl
  
  # å…¨é‡æ›¿æ¢ - åˆ é™¤æ‰€æœ‰æ—§æ•°æ®ï¼Œå¯¼å…¥æ–°æ•°æ®ï¼ˆæ¨èç”¨äºå®šæ—¶ä»»åŠ¡ï¼‰
  FULL_REPLACE=true python scripts/import_eyeuc_jsonl_to_mysql.py "per_list_output/*.jsonl"
  
  # å…¨é‡æ›¿æ¢ + ç¦ç”¨æ¸…ç†ï¼ˆç”¨äºè°ƒè¯•ï¼‰
  FULL_REPLACE=true CLEANUP=false python scripts/import_eyeuc_jsonl_to_mysql.py "per_list_output/*.jsonl"

ç¯å¢ƒå˜é‡ï¼š
  MYSQL_HOST, MYSQL_PORT, MYSQL_USER, MYSQL_PASSWORD, MYSQL_DATABASE - æ•°æ®åº“è¿æ¥
  CLEANUP=true/false - å¯¼å…¥æˆåŠŸåè‡ªåŠ¨æ¸…ç†æºæ–‡ä»¶ï¼ˆé»˜è®¤ trueï¼‰
  FULL_REPLACE=true/false - å…¨é‡æ›¿æ¢æ¨¡å¼ï¼ˆé»˜è®¤ falseï¼‰
"""

import os
import sys
import glob
import json
import time
from datetime import datetime
from pathlib import Path

try:
    import pymysql
except ImportError:
    print("âŒ ç¼ºå°‘ä¾èµ–ï¼špip install pymysql python-dotenv")
    sys.exit(1)

try:
    from dotenv import load_dotenv
    # è‡ªåŠ¨åŠ è½½ .env æ–‡ä»¶
    load_dotenv()
except ImportError:
    # å¦‚æœæ²¡æœ‰å®‰è£… python-dotenvï¼Œä»ç„¶å¯ä»¥é€šè¿‡æ‰‹åŠ¨ export ç¯å¢ƒå˜é‡è¿è¡Œ
    pass


def get_conn():
    """åˆ›å»ºæ•°æ®åº“è¿æ¥"""
    ssl_disabled = os.getenv("MYSQL_SSL", "false").lower() in ("false", "0", "no")
    
    conn_params = {
        'host': os.getenv("MYSQL_HOST", "localhost"),
        'port': int(os.getenv("MYSQL_PORT", "3306")),
        'user': os.getenv("MYSQL_USER", "root"),
        'password': os.getenv("MYSQL_PASSWORD", ""),
        'database': os.getenv("MYSQL_DATABASE", "eyeuc"),
        'charset': "utf8mb4",
        'cursorclass': pymysql.cursors.DictCursor,
        'autocommit': False,
    }
    
    # SSL é…ç½®
    if not ssl_disabled:
        conn_params['ssl'] = {'ssl': {}}
    
    return pymysql.connect(**conn_params)


def ensure_schema(conn):
    """ç¡®ä¿è¡¨ç»“æ„å­˜åœ¨"""
    schema_file = Path(__file__).parent.parent / "schema.sql"
    
    if not schema_file.exists():
        print(f"âš ï¸  æœªæ‰¾åˆ° schema.sql: {schema_file}")
        return
    
    print(f"ğŸ“‹ æ‰§è¡Œè¡¨ç»“æ„: {schema_file}")
    
    with open(schema_file, 'r', encoding='utf-8') as f:
        sql_content = f.read()
    
    # åˆ†å‰²å¹¶æ‰§è¡Œæ¯æ¡ SQL
    statements = []
    current = []
    
    for line in sql_content.split('\n'):
        line = line.strip()
        
        # è·³è¿‡æ³¨é‡Š
        if line.startswith('--') or not line:
            continue
        
        current.append(line)
        
        # é‡åˆ°åˆ†å·ï¼Œæ‰§è¡Œä¸€æ¡ SQL
        if line.endswith(';'):
            statements.append(' '.join(current))
            current = []
    
    with conn.cursor() as cur:
        for stmt in statements:
            if stmt.strip():
                try:
                    cur.execute(stmt)
                except Exception as e:
                    print(f"âš ï¸  SQL æ‰§è¡Œè­¦å‘Š: {e}")
    
    conn.commit()
    print("âœ… è¡¨ç»“æ„å°±ç»ª\n")


def parse_int(v):
    """å®‰å…¨è§£ææ•´æ•°"""
    if v is None:
        return None
    try:
        # ç§»é™¤é€—å·å’Œç©ºæ ¼
        return int(str(v).replace(",", "").strip())
    except:
        return None


def parse_dt(v):
    """å®‰å…¨è§£ææ—¥æœŸæ—¶é—´"""
    if not v:
        return None
    
    # å°è¯•å¤šç§æ ¼å¼
    formats = [
        "%Y-%m-%d %H:%M",
        "%Y-%m-%d %H:%M:%S",
        "%Y-%m-%d",
        "%Y-%m-%d %H:%M:%S.%f",
    ]
    
    for fmt in formats:
        try:
            return datetime.strptime(v.strip(), fmt)
        except:
            pass
    
    return None


def upsert_list(conn, list_id, game):
    """æ’å…¥æˆ–æ›´æ–°åˆ—è¡¨"""
    with conn.cursor() as cur:
        cur.execute("""
            INSERT INTO lists (list_id, game, slug)
            VALUES (%s, %s, NULL)
            ON DUPLICATE KEY UPDATE 
                game=VALUES(game),
                updated_at=CURRENT_TIMESTAMP
        """, (list_id, game))


def upsert_mod(conn, item):
    """æ’å…¥æˆ–æ›´æ–°èµ„æºä¸»è¡¨"""
    md = item.get("metadata", {})
    
    with conn.cursor() as cur:
        cur.execute("""
            INSERT INTO mods
            (mid, list_id, category, title, intro_html, cover_image, 
             author, author_url, publisher, publisher_url,
             views, downloads, likes, 
             created_at, last_updated, 
             detail_url, list_url, raw_json)
            VALUES
            (%s, %s, %s, %s, %s, %s, 
             %s, %s, %s, %s, 
             %s, %s, %s, 
             %s, %s, 
             %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                category=VALUES(category),
                title=VALUES(title), 
                intro_html=VALUES(intro_html), 
                cover_image=VALUES(cover_image),
                author=VALUES(author), 
                author_url=VALUES(author_url),
                publisher=VALUES(publisher), 
                publisher_url=VALUES(publisher_url),
                views=VALUES(views), 
                downloads=VALUES(downloads), 
                likes=VALUES(likes),
                created_at=VALUES(created_at), 
                last_updated=VALUES(last_updated),
                detail_url=VALUES(detail_url), 
                list_url=VALUES(list_url),
                raw_json=VALUES(raw_json)
        """, (
            parse_int(item["mid"]), 
            parse_int(item["list_id"]), 
            item.get("category"),  # åˆ†ç±»
            item.get("title"),
            item.get("intro"), 
            item.get("cover_image"),
            md.get("author"), 
            md.get("author_url"),
            md.get("publisher"), 
            md.get("publisher_url"),
            parse_int(md.get("views")), 
            parse_int(md.get("downloads")), 
            parse_int(md.get("likes")),
            parse_dt(md.get("created_at")), 
            parse_dt(md.get("last_updated") or md.get("current_version_updated")),
            item.get("detail_url"), 
            item.get("list_url"),
            json.dumps(item, ensure_ascii=False).encode('utf-8'),
        ))


def upsert_images(conn, mod_id, images):
    """æ’å…¥æˆ–æ›´æ–°å›¾ç‰‡"""
    if not images:
        return
    
    with conn.cursor() as cur:
        for idx, url in enumerate(images):
            if not url:
                continue
            
            cur.execute("""
                INSERT INTO images (mod_id, url, idx)
                VALUES (%s, %s, %s)
                ON DUPLICATE KEY UPDATE idx=VALUES(idx)
            """, (mod_id, url, idx))


def upsert_versions_and_downloads(conn, mod_id, versions):
    """æ’å…¥æˆ–æ›´æ–°ç‰ˆæœ¬å’Œä¸‹è½½"""
    if not versions:
        return
    
    with conn.cursor() as cur:
        for ver in versions:
            vid = parse_int(ver.get("vid"))
            
            # æ’å…¥ç‰ˆæœ¬
            cur.execute("""
                INSERT INTO versions
                (mod_id, vid, version_name, is_default, intro, 
                 updated_at, views, downloads)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                ON DUPLICATE KEY UPDATE
                    version_name=VALUES(version_name),
                    is_default=VALUES(is_default),
                    intro=VALUES(intro),
                    updated_at=VALUES(updated_at),
                    views=VALUES(views),
                    downloads=VALUES(downloads)
            """, (
                mod_id, 
                vid, 
                ver.get("version_name"),
                1 if ver.get("is_default") else 0,
                ver.get("intro"),
                parse_dt((ver.get("stats") or {}).get("updated_at")),
                parse_int((ver.get("stats") or {}).get("views")),
                parse_int((ver.get("stats") or {}).get("downloads")),
            ))
            
            # è·å– version_id
            cur.execute("""
                SELECT id FROM versions 
                WHERE mod_id=%s AND (vid <=> %s OR (vid IS NULL AND %s IS NULL))
                ORDER BY id DESC LIMIT 1
            """, (mod_id, vid, vid))
            
            ver_row = cur.fetchone()
            version_id = ver_row["id"] if ver_row else None
            
            # æ’å…¥ä¸‹è½½
            for dl in ver.get("downloads", []):
                # åˆ¤æ–­ç±»å‹ï¼šæœ‰ fileid çš„æ˜¯ internalï¼Œå¦åˆ™æ˜¯ external
                dl_type = dl.get("type")
                if not dl_type:
                    dl_type = "internal" if dl.get("fileid") else "external"
                
                # å¤„ç†å¤–é“¾çš„ name å­—æ®µ
                note = dl.get("note") or dl.get("name")
                
                cur.execute("""
                    INSERT INTO downloads
                    (mod_id, version_id, type, 
                     fileid, filename, size, 
                     url, note, version_label)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON DUPLICATE KEY UPDATE
                        filename=VALUES(filename), 
                        size=VALUES(size), 
                        note=VALUES(note), 
                        version_label=VALUES(version_label)
                """, (
                    mod_id, 
                    version_id, 
                    dl_type,
                    parse_int(dl.get("fileid")), 
                    dl.get("filename"), 
                    dl.get("size"),
                    dl.get("url"), 
                    note, 
                    dl.get("version"),
                ))


def iter_items_from_file(path):
    """ä»æ–‡ä»¶ä¸­è¿­ä»£ itemsï¼ˆæ”¯æŒ JSONL å’Œ JSON æ•°ç»„ï¼‰"""
    try:
        with open(path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        
        if not content:
            return
        
        # åˆ¤æ–­æ ¼å¼
        if content.startswith('['):
            # JSON æ•°ç»„
            data = json.loads(content)
            for item in data:
                yield item
        else:
            # JSONL
            for line in content.split('\n'):
                line = line.strip()
                if line:
                    yield json.loads(line)
    
    except Exception as e:
        print(f"  âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")


def cleanup_imported_files(files):
    """æ¸…ç†å·²æˆåŠŸå¯¼å…¥çš„æ–‡ä»¶
    
    Args:
        files: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    if not files:
        return
    
    print("ğŸ§¹ æ¸…ç†å·²å¯¼å…¥çš„æ–‡ä»¶...")
    
    # è·å–æ‰€æœ‰æ¶‰åŠçš„ç›®å½•ï¼ˆç”¨äºåç»­æ£€æŸ¥æ˜¯å¦æ¸…ç©ºï¼‰
    dirs_to_check = set()
    for file_path in files:
        try:
            file_obj = Path(file_path)
            if file_obj.exists():
                os.remove(file_path)
                print(f"  âœ… åˆ é™¤: {file_obj.name}")
                dirs_to_check.add(file_obj.parent)
        except Exception as e:
            print(f"  âš ï¸  åˆ é™¤å¤±è´¥ {Path(file_path).name}: {e}")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœä¸ºç©ºåˆ™åˆ é™¤
    for dir_path in dirs_to_check:
        try:
            if dir_path.exists() and dir_path.is_dir():
                remaining = list(dir_path.glob('*'))
                if not remaining:
                    print(f"  ğŸ“ ç›®å½•å·²ç©ºï¼Œåˆ é™¤: {dir_path.name}")
                    dir_path.rmdir()
                else:
                    print(f"  ğŸ“ ç›®å½•ä¿ç•™ï¼ˆè¿˜æœ‰ {len(remaining)} ä¸ªæ–‡ä»¶ï¼‰: {dir_path.name}")
        except Exception as e:
            print(f"  âš ï¸  æ£€æŸ¥ç›®å½•å¤±è´¥ {dir_path}: {e}")
    
    print("âœ¨ æ¸…ç†å®Œæˆ\n")


def import_files(glob_pattern, batch_size=200, auto_cleanup=True, full_replace=False):
    """å¯¼å…¥æ–‡ä»¶
    
    Args:
        glob_pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼
        batch_size: æ‰¹é‡æäº¤å¤§å°
        auto_cleanup: å¯¼å…¥æˆåŠŸåè‡ªåŠ¨æ¸…ç†æºæ–‡ä»¶ï¼ˆé»˜è®¤ Trueï¼‰
        full_replace: å¯¼å…¥å‰å…ˆåˆ é™¤æ‰€æœ‰æ—§æ•°æ®ï¼ˆé»˜è®¤ Falseï¼‰
    """
    # å±•å¼€ glob
    files = sorted(glob.glob(glob_pattern))
    
    if not files:
        print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶: {glob_pattern}")
        return False
    
    print(f"ğŸ“ æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶:")
    for f in files:
        print(f"  - {Path(f).name}")
    print()
    
    # è¿æ¥æ•°æ®åº“
    print("ğŸ”Œ è¿æ¥æ•°æ®åº“...")
    conn = get_conn()
    print(f"âœ… å·²è¿æ¥: {os.getenv('MYSQL_HOST')}:{os.getenv('MYSQL_PORT')}/{os.getenv('MYSQL_DATABASE')}\n")
    
    # ç¡®ä¿è¡¨ç»“æ„
    ensure_schema(conn)
    
    # å…¨é‡æ›¿æ¢ï¼šåˆ é™¤æ‰€æœ‰æ—§æ•°æ®
    if full_replace:
        print("ğŸ—‘ï¸  å…¨é‡æ›¿æ¢æ¨¡å¼ï¼šåˆ é™¤æ‰€æœ‰æ—§æ•°æ®...")
        try:
            with conn.cursor() as cur:
                # ç¦ç”¨å¤–é”®æ£€æŸ¥ï¼ŒåŠ å¿«åˆ é™¤é€Ÿåº¦
                cur.execute("SET FOREIGN_KEY_CHECKS=0")
                
                # æ¸…ç©ºæ‰€æœ‰è¡¨ï¼ˆæŒ‰é¡ºåºï¼‰
                tables = ['downloads', 'versions', 'images', 'mods', 'lists']
                for table in tables:
                    cur.execute(f"TRUNCATE TABLE {table}")
                    print(f"  âœ… æ¸…ç©ºè¡¨: {table}")
                
                # æ¢å¤å¤–é”®æ£€æŸ¥
                cur.execute("SET FOREIGN_KEY_CHECKS=1")
            
            conn.commit()
            print("âœ… æ‰€æœ‰æ—§æ•°æ®å·²åˆ é™¤\n")
        except Exception as e:
            print(f"âŒ åˆ é™¤æ—§æ•°æ®å¤±è´¥: {e}")
            conn.rollback()
            raise
    
    # å¯¼å…¥æ•°æ®
    total_items = 0
    batch_count = 0
    start_time = time.time()
    import_success = False
    
    try:
        for file_path in files:
            print(f"ğŸ“„ å¤„ç†: {Path(file_path).name}")
            
            file_items = 0
            for item in iter_items_from_file(file_path):
                try:
                    list_id = parse_int(item.get("list_id"))
                    game = item.get("game") or f"list_{list_id}"
                    mid = parse_int(item.get("mid"))
                    
                    if not list_id or not mid:
                        print(f"  âš ï¸  è·³è¿‡æ— æ•ˆ item: list_id={list_id}, mid={mid}")
                        continue
                    
                    # æ’å…¥æ•°æ®
                    upsert_list(conn, list_id, game)
                    upsert_mod(conn, item)
                    upsert_images(conn, mid, item.get("images"))
                    upsert_versions_and_downloads(conn, mid, item.get("versions"))
                    
                    total_items += 1
                    file_items += 1
                    batch_count += 1
                    
                    # æ‰¹é‡æäº¤
                    if batch_count >= batch_size:
                        conn.commit()
                        print(f"  ğŸ’¾ å·²æäº¤ {total_items} items")
                        batch_count = 0
                
                except Exception as e:
                    print(f"  âŒ å¤„ç† item å¤±è´¥: {e}")
                    conn.rollback()
            
            print(f"  âœ… å®Œæˆ: {file_items} items\n")
        
        # æœ€åæäº¤
        conn.commit()
        import_success = True
        
        elapsed = time.time() - start_time
        print(f"{'='*80}")
        print(f"ğŸ‰ å¯¼å…¥å®Œæˆ!")
        print(f"{'='*80}")
        print(f"  æ€» items: {total_items}")
        print(f"  æ€»æ–‡ä»¶: {len(files)}")
        print(f"  ç”¨æ—¶: {elapsed:.2f}s")
        print(f"  é€Ÿåº¦: {total_items/elapsed:.1f} items/s")
        print(f"{'='*80}\n")
        
        # è‡ªåŠ¨æ¸…ç†æºæ–‡ä»¶
        if import_success and auto_cleanup:
            cleanup_imported_files(files)
        
        return True
    
    except Exception as e:
        print(f"\nâŒ å¯¼å…¥å¤±è´¥: {e}")
        conn.rollback()
        raise
    
    finally:
        conn.close()


def main():
    if len(sys.argv) < 2:
        print(__doc__)
        print("\nâŒ ç¼ºå°‘å‚æ•°")
        print("\nç”¨æ³•: python scripts/import_eyeuc_jsonl_to_mysql.py <glob_pattern>")
        print('\nç¤ºä¾‹: python scripts/import_eyeuc_jsonl_to_mysql.py "per_list_output/eyeuc_list193_*.jsonl"')
        sys.exit(1)
    
    glob_pattern = sys.argv[1]
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    required_env = ['MYSQL_HOST', 'MYSQL_USER', 'MYSQL_PASSWORD', 'MYSQL_DATABASE']
    missing = [e for e in required_env if not os.getenv(e)]
    
    if missing:
        print(f"âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡: {', '.join(missing)}")
        print("\nè¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–åˆ›å»º .env æ–‡ä»¶:")
        print("  export MYSQL_HOST=your_host")
        print("  export MYSQL_PORT=3306")
        print("  export MYSQL_USER=your_user")
        print("  export MYSQL_PASSWORD=your_password")
        print("  export MYSQL_DATABASE=your_database")
        print("  export MYSQL_SSL=false")
        print("  export CLEANUP=true  # è‡ªåŠ¨æ¸…ç†æºæ–‡ä»¶ï¼ˆé»˜è®¤ï¼‰")
        print("\næˆ–ä½¿ç”¨: source .env")
        sys.exit(1)
    
    # è¯»å– CLEANUP ç¯å¢ƒå˜é‡ï¼ˆé»˜è®¤ trueï¼‰
    auto_cleanup = os.getenv('CLEANUP', 'true').lower() not in ('false', '0', 'no')
    
    # è¯»å– FULL_REPLACE ç¯å¢ƒå˜é‡ï¼ˆé»˜è®¤ falseï¼‰
    full_replace = os.getenv('FULL_REPLACE', 'false').lower() in ('true', '1', 'yes')
    
    # æ˜¾ç¤ºæ¨¡å¼æç¤º
    if full_replace:
        print("âš ï¸  " + "=" * 76)
        print("âš ï¸  å…¨é‡æ›¿æ¢æ¨¡å¼ï¼šå°†åˆ é™¤æ‰€æœ‰æ—§æ•°æ®ï¼Œç„¶åå¯¼å…¥æ–°æ•°æ®")
        print("âš ï¸  " + "=" * 76)
        print()
    
    import_files(glob_pattern, auto_cleanup=auto_cleanup, full_replace=full_replace)


if __name__ == "__main__":
    main()

